{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3097b507-869b-4242-b9ec-c45fb9af2d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score, log_loss, classification_report\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d379da79-1bdc-451c-af09-65335858d1d5",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c1224fb-b57c-428b-9f95-76626ea70608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(470342, 125)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = r\"C:\\Users\\matta\\Desktop\\Documents\\Python\\Geolocation\\climate_data\\working_data\\clean_labeled_climate_data.pkl\"\n",
    "df = pd.read_pickle(path)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "521885f1-0b55-4b0f-9057-ebe236f858cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_precip_cols = ['longitude', 'latitude',\n",
    "                    'jan_precip', 'feb_precip', 'mar_precip', 'apr_precip', 'may_precip', 'jun_precip', \n",
    "                    'jul_precip', 'aug_precip', 'sep_precip', 'oct_precip', 'nov_precip', 'dec_precip',  \n",
    "                    'jan_meant', 'feb_meant', 'mar_meant', 'apr_meant', 'may_meant', 'jun_meant', \n",
    "                    'jul_meant', 'aug_meant', 'sep_meant', 'oct_meant', 'nov_meant', 'dec_meant']\n",
    "select_cols = ['longitude', 'latitude', 'jan_tmin', 'jul_maxt', 'jan_dptmean', 'jul_dptmean', 'annual_precip']\n",
    "target_cols = ['Level_1', 'Level_2', 'Level_3', 'Level_4', 'ECO_NAME', 'climates_f']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679e5486-3b1c-4915-82fd-0fc4b9cd9300",
   "metadata": {},
   "source": [
    "# Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "368b9357-5f7a-495b-bed0-3e03e0d06df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[temp_precip_cols + ['jan_tmin', 'jul_maxt', 'jan_dptmean', 'jul_dptmean', 'annual_precip']]\n",
    "y = df.Level_1\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7359c67c-79d3-45b3-b08d-045a3b3e7dc1",
   "metadata": {},
   "source": [
    "# EPA Level 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6ff8dad-78a7-4177-bc91-6bc7802552b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.25, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb63a6c-a279-420c-a1f2-b856c3d5eeea",
   "metadata": {},
   "source": [
    "## XGBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e5b8fd-eabd-4396-b046-ff42be618f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-28 19:54:55,150] A new study created in memory with name: no-name-5964f2d2-1629-4a70-a21c-570a05091a20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9d2139c5e944f33926534c53401b70d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define Optuna objective function\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 200, 800),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0, 2.0),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0.1, 5.0),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0.0, 1.0),\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"objective\": \"multi:softprob\",\n",
    "        \"num_class\": len(np.unique(y_train)),\n",
    "        \"random_state\": 42,\n",
    "        \"eval_metric\": \"mlogloss\",\n",
    "        \"n_jobs\": -1\n",
    "    }\n",
    "\n",
    "    model = XGBClassifier(**params)\n",
    "\n",
    "    model.fit(X_train, y_train,\n",
    "              eval_set=[(X_test, y_test)],\n",
    "              verbose=False)\n",
    "\n",
    "    # Predict probabilities\n",
    "    y_pred_proba = model.predict_proba(X_test)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluate performance\n",
    "    logloss = log_loss(y_test, y_pred_proba)\n",
    "    f1_macro = f1_score(y_test, y_pred, average=\"macro\")\n",
    "\n",
    "    # We minimize logloss but can return a combined objective\n",
    "    # Optuna always minimizes, so we can return logloss or -f1 to maximize f1\n",
    "    return logloss\n",
    "\n",
    "# Run Optuna study\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=30, show_progress_bar=True)\n",
    "\n",
    "# Best trial summary\n",
    "print(\"Best Trial:\")\n",
    "print(f\"  Log Loss: {study.best_value:.4f}\")\n",
    "print(\"  Best Params:\")\n",
    "for key, value in study.best_params.items():\n",
    "    print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d658e8-eca0-4c42-870b-f739d1eeed0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain final model with best params\n",
    "best_params = study.best_params\n",
    "best_model = XGBClassifier(\n",
    "    **best_params,\n",
    "    objective=\"multi:softprob\",\n",
    "    num_class=len(np.unique(y_train)),\n",
    "    eval_metric=\"mlogloss\",\n",
    "    tree_method=\"hist\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate final model\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_proba = best_model.predict_proba(X_test)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1_macro = f1_score(y_test, y_pred, average=\"macro\")\n",
    "ll = log_loss(y_test, y_pred_proba)\n",
    "\n",
    "print(f\"\\n✅ Final Accuracy: {acc:.3f}\")\n",
    "print(f\"✅ Final F1 (macro): {f1_macro:.3f}\")\n",
    "print(f\"✅ Final Log Loss: {ll:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa777280-a3d6-4df5-8dff-394f51c827dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
